{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "my_list=[1,2]\n",
    "e=1\n",
    "# 假设列表为 my_list\n",
    "file_path = os.path.join('../result/', f'my_list_{e}.pkl')  # 文件路径为 result/my_list.pkl\n",
    "\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(my_list, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.0253,  2.4540, -0.9299,  0.3203,  1.2779],\n",
       "         [ 0.0957, -0.0838,  6.0922,  1.5990,  0.4150],\n",
       "         [-0.7917, -1.7844, -2.7360,  0.0079, -3.1418],\n",
       "         [ 1.0139, -2.5167,  0.0997,  2.0076,  0.3560],\n",
       "         [-0.3350, -0.1313,  1.4936,  0.1405, -0.5117]], dtype=torch.float64),\n",
       " tensor([[ 0.4154, -0.1231, -0.0840,  3.3802,  0.0212],\n",
       "         [ 2.1378, -0.2380,  2.1818,  2.8994, -0.0779],\n",
       "         [-0.0632,  0.2164,  0.4578, -0.0243, -1.8013],\n",
       "         [-0.3919,  0.0058,  0.8350,  3.4534, -3.8682],\n",
       "         [-0.1007,  0.7516, -0.9256, -0.6446,  1.4835]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def generate_grads_with_privacy_ldp(grads, num_selected, clip_norm, epsilon):\n",
    "    if num_selected > 0:\n",
    "        total_norm = torch.norm(torch.stack([torch.norm(g.detach()) for g in grads]))\n",
    "        clip_coef = clip_norm / (total_norm + 1e-6)\n",
    "        if clip_coef < 1:\n",
    "            grads = [g * clip_coef for g in grads]\n",
    "\n",
    "    for i in range(len(grads)):\n",
    "        grads[i] = grads[i] + np.random.laplace(0, clip_norm/epsilon, size=grads[i].shape)\n",
    "\n",
    "    return grads\n",
    "\n",
    "# 梯度列表\n",
    "grads = [torch.rand((5, 5)), torch.rand((5, 5))]\n",
    "\n",
    "# 选定的裁剪数\n",
    "num_selected = 2\n",
    "\n",
    "# 裁剪范数\n",
    "clip_norm = 0.1\n",
    "\n",
    "# 隐私预算\n",
    "epsilon = 0.1\n",
    "\n",
    "# 添加隐私\n",
    "private_grads = generate_grads_with_privacy_ldp(grads, num_selected, clip_norm, epsilon)\n",
    "private_grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "1.0\n",
      "1.5\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "# 0.5的隐私预算下，4次cdp/ldp/真实 的梯度统计。 shapley值统计\n",
    "# 然后进行均值 然后进行mse差值比较\n",
    "for epsilon in range(5, 21, 5):\n",
    "    epsilon = round(epsilon / 10, 1)\n",
    "    print(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('fl_incentive')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6afacf2f60fb0e85c06097d06e98cad29769449a84e7b54e6285731cd4887ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
